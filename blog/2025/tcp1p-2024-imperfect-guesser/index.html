<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> TCP1P 2024 - Imperfect Guesser | Joshua R. Sylvester </title> <meta name="author" content="Joshua R. Sylvester"> <meta name="description" content="Write up from the TCP1P 2024 CTF competition"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.png?caebac7e1dc792c0cd262ee032d8e29f"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://jsylvester.com/blog/2025/tcp1p-2024-imperfect-guesser/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Joshua</span> R. Sylvester </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/news/">news </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">TCP1P 2024 - Imperfect Guesser</h1> <p class="post-meta"> Created on August 15, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/reverse"> <i class="fa-solid fa-hashtag fa-sm"></i> reverse</a>   ·   <a href="/blog/category/write-ups"> <i class="fa-solid fa-tag fa-sm"></i> write-ups</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <ul> <li>CTF: TCP1P 2024</li> <li>Challenge Name: Imperfect Guesser</li> <li>Category: Reverse</li> <li>Difficulty: Unknown</li> </ul> <h2 id="synopsis">Synopsis</h2> <p>Use gradient descent to reverse-engineer a PyTorch model, aiming to recover the input from a given output to retrieve a hidden flag</p> <h2 id="description">Description</h2> <p>Leaving a floating secret crumbs with the help of untrained labour, now “guess” the flag.</p> <h2 id="challenge">Challenge</h2> <p>The challenge contains one file:</p> <ul> <li> <code class="language-plaintext highlighter-rouge">chally.py</code>: This is the main file that hides the flag by passing it through a PyTorch model</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span><span class="p">,</span> <span class="n">random</span>
<span class="kn">import</span> <span class="n">torch.nn</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">flag</span> <span class="o">=</span> <span class="sh">"</span><span class="s">TCP1P{REDACTED}</span><span class="sh">"</span>

<span class="k">def</span> <span class="nf">floatify</span><span class="p">(</span><span class="n">ip</span><span class="p">):</span>
	<span class="n">flag</span> <span class="o">=</span> <span class="p">[</span><span class="nf">float</span><span class="p">(</span><span class="nf">ord</span><span class="p">(</span><span class="n">i</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ip</span><span class="p">]</span>
	<span class="n">normalized</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="n">flag</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
	<span class="k">return</span> <span class="n">normalized</span>

<span class="k">def</span> <span class="nf">tf</span><span class="p">(</span><span class="n">_in</span><span class="p">,</span><span class="n">_out</span><span class="p">):</span>
	<span class="n">weight</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">round</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="n">_out</span><span class="p">,</span> <span class="n">_in</span><span class="p">)).</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">),</span><span class="mi">2</span><span class="p">)</span>
	<span class="n">bias</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">round</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">_out</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">),</span><span class="mi">2</span><span class="p">)</span>
	<span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">from_numpy</span><span class="p">(</span><span class="n">weight</span><span class="p">),</span> <span class="n">torch</span><span class="p">.</span><span class="nf">from_numpy</span><span class="p">(</span><span class="n">bias</span><span class="p">)</span>

<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="mh">0x544350</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
	<span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="mi">450</span><span class="p">),</span>
	<span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">450</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span>
	<span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">17</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">layer_shapes</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">24</span><span class="p">,</span> <span class="mi">450</span><span class="p">),</span> <span class="p">(</span><span class="mi">450</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">17</span><span class="p">)]</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">layer_shapes</span><span class="p">):</span>
	<span class="n">weight</span><span class="p">,</span> <span class="n">bias</span> <span class="o">=</span> <span class="nf">tf</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>
	<span class="n">model</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">weight</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">weight</span>
	<span class="n">model</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">bias</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">bias</span>
 
<span class="nf">print</span><span class="p">([</span><span class="n">i</span><span class="p">.</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">().</span><span class="nf">tolist</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">model</span><span class="p">(</span><span class="nf">floatify</span><span class="p">(</span><span class="n">flag</span><span class="p">))[</span><span class="mi">0</span><span class="p">]])</span>
<span class="c1"># Output:
# [38883.9140625, 18747.87890625, -15371.05078125, 12231.2080078125, -56379.48046875, -33719.13671875, 9454.150390625, 9346.9814453125, 1701.4693603515625, -6380.3759765625, 12019.501953125, -4850.94140625, 14421.296875, 44332.0390625, -11196.283203125, -19712.0859375, -36390.265625]
</span></code></pre></div></div> <h2 id="solution">Solution</h2> <h3 id="problem-setup">Problem Setup</h3> <p>In this scenario, the model has been trained to map a 24-character input (representing the flag) to a 17-dimensional output. The challenge is to reverse the process: given the output, recover the original input (the flag).</p> <p>The flag format follows a known structure:</p> <ul> <li>The first six characters are <code class="language-plaintext highlighter-rouge">"TCP1P{"</code>.</li> <li>The last character is <code class="language-plaintext highlighter-rouge">"}"</code>.</li> <li>The remaining 17 characters need to be inferred.</li> </ul> <h3 id="step-1-target-output-setup">Step 1: Target Output Setup</h3> <p>First, we define the target output, which is the known output from the model for a specific input.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">output</span> <span class="o">=</span> <span class="p">[</span><span class="mf">38883.9140625</span><span class="p">,</span> <span class="mf">18747.87890625</span><span class="p">,</span> <span class="o">-</span><span class="mf">15371.05078125</span><span class="p">,</span> <span class="mf">12231.2080078125</span><span class="p">,</span> <span class="o">-</span><span class="mf">56379.48046875</span><span class="p">,</span>
          <span class="o">-</span><span class="mf">33719.13671875</span><span class="p">,</span> <span class="mf">9454.150390625</span><span class="p">,</span> <span class="mf">9346.9814453125</span><span class="p">,</span> <span class="mf">1701.4693603515625</span><span class="p">,</span> <span class="o">-</span><span class="mf">6380.3759765625</span><span class="p">,</span>
          <span class="mf">12019.501953125</span><span class="p">,</span> <span class="o">-</span><span class="mf">4850.94140625</span><span class="p">,</span> <span class="mf">14421.296875</span><span class="p">,</span> <span class="mf">44332.0390625</span><span class="p">,</span> <span class="o">-</span><span class="mf">11196.283203125</span><span class="p">,</span>
          <span class="o">-</span><span class="mf">19712.0859375</span><span class="p">,</span> <span class="o">-</span><span class="mf">36390.265625</span><span class="p">]</span>

<span class="c1"># Convert the output into a format PyTorch can use
</span><span class="n">target_output</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="n">output</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
</code></pre></div></div> <p>The <code class="language-plaintext highlighter-rouge">output</code> list represents the expected result from the neural network. We convert it into a PyTorch tensor so it can be used as a target for optimisation.</p> <h3 id="step-2-constructing-an-initial-flag-candidate">Step 2: Constructing an Initial Flag Candidate</h3> <p>We know the first six and last characters of the flag, but the 17 characters in the middle are unknown. We start by randomly initialising these 17 characters.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Known characters of the flag
</span><span class="n">first_six_chars</span> <span class="o">=</span> <span class="sh">"</span><span class="s">TCP1P{</span><span class="sh">"</span>  <span class="c1"># Known prefix
</span><span class="n">last_char</span> <span class="o">=</span> <span class="sh">"</span><span class="s">}</span><span class="sh">"</span>              <span class="c1"># Known suffix
</span>
<span class="c1"># Construct the initial flag candidate
</span><span class="n">known_chars</span> <span class="o">=</span> <span class="p">[</span><span class="nf">ord</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">first_six_chars</span><span class="p">]</span>
<span class="n">middle_length</span> <span class="o">=</span> <span class="mi">17</span>  <span class="c1"># Total length is 24; 6 + middle + 1 = 24, so 17 middle characters
</span><span class="n">middle_chars</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">middle_length</span><span class="p">)).</span><span class="nf">tolist</span><span class="p">()</span>  <span class="c1"># Random initial middle characters
</span><span class="n">known_chars</span> <span class="o">+=</span> <span class="n">middle_chars</span> <span class="o">+</span> <span class="p">[</span><span class="nf">ord</span><span class="p">(</span><span class="n">last_char</span><span class="p">)]</span>

<span class="c1"># Create an input tensor with the known characters
</span><span class="n">input_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="n">known_chars</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div> <p>Here, we initialise the middle part of the flag randomly and combine it with the known prefix and suffix. The complete flag candidate is stored in a PyTorch tensor, and gradients are enabled for optimisation.</p> <h3 id="step-3-setting-up-the-optimiser">Step 3: Setting Up the Optimiser</h3> <p>We use the Adam optimizer to iteratively adjust the input tensor to minimize the difference between the model’s output for the current flag candidate and the target output.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Optimiser setup
</span><span class="n">optimiser</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">([</span><span class="n">input_tensor</span><span class="p">],</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>  <span class="c1"># Learning rate
</span></code></pre></div></div> <p>The learning rate controls the step size during optimisation. Setting it to 0.1 allows for gradual adjustments.</p> <h3 id="step-4-gradient-descent-optimisation">Step 4: Gradient Descent Optimisation</h3> <p>The goal of this step is to iteratively refine the input tensor so that the model’s output matches the target output as closely as possible. This is done by minimising the mean squared error (MSE) loss.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Number of iterations for optimisation
</span><span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">50000</span>

<span class="c1"># Gradient-based optimisation loop
</span><span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">):</span>
    <span class="n">optimiser</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>  <span class="c1"># Zero out the gradients
</span>
    <span class="c1"># Forward pass through the model
</span>    <span class="n">output</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>

    <span class="c1"># Compute the loss
</span>    <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">mse_loss</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target_output</span><span class="p">)</span>
    
    <span class="c1"># If loss is zero break from the training loop
</span>    <span class="k">if</span> <span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">:</span>
        <span class="k">break</span>

    <span class="c1"># Backward pass (compute gradients)
</span>    <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>

    <span class="c1"># Gradient update step
</span>    <span class="n">optimiser</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>

    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
        <span class="c1"># Ensure the first six and last character are fixed
</span>        <span class="n">input_tensor</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:</span><span class="mi">6</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="nf">ord</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">first_six_chars</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">input_tensor</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="nf">ord</span><span class="p">(</span><span class="n">last_char</span><span class="p">)</span>

    <span class="c1"># Print progress
</span>    <span class="k">if</span> <span class="n">iteration</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Iteration </span><span class="si">{</span><span class="n">iteration</span><span class="si">}</span><span class="s">, Loss: </span><span class="si">{</span><span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <ul> <li>The optimiser updates the input tensor based on the gradients of the loss function with respect to the input.</li> <li>To maintain the known structure of the flag, the first six and last characters are kept fixed after each update.</li> <li>The process continues for a maximum of 50,000 iterations or until the loss reaches zero.</li> </ul> <h3 id="step-5-converting-the-optimised-tensor-back-to-a-flag">Step 5: Converting the Optimised Tensor Back to a Flag</h3> <p>Finally, we convert the adjusted input tensor into a string that represents the optimised flag candidate.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Convert the optimised input tensor back to a flag candidate
</span><span class="n">optimised_flag</span> <span class="o">=</span> <span class="sh">""</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="nf">chr</span><span class="p">(</span><span class="nf">int</span><span class="p">(</span><span class="nf">round</span><span class="p">(</span><span class="n">c</span><span class="p">)))</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">input_tensor</span><span class="p">.</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Optimised Flag Candidate: </span><span class="si">{</span><span class="n">optimised_flag</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <p>After the optimisation loop, we round the values in the tensor to the nearest integers and convert them to characters, forming the recovered flag.</p> <h3 id="summary">Summary</h3> <p>This code attempts to reverse the neural network’s behaviour by finding an input (flag) that produces a given output. It leverages gradient descent to minimise the error between the model’s output for the current input and the target output, adjusting the input iteratively while keeping certain known characters fixed. The process is complete when the loss reaches zero, indicating successful flag recovery.</p> <h3 id="output">Output</h3> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Iteration 0, Loss: 132506472.0
Iteration 100, Loss: 84305080.0
Iteration 200, Loss: 51630704.0
Iteration 300, Loss: 30629590.0
...
Iteration 49900, Loss: 0.006987122818827629
Optimised Flag Candidate: TCP1P{1ts_tr3ndy_NN_n0w}
</code></pre></div></div> <h2 id="solution-code">Solution Code</h2> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span><span class="p">,</span> <span class="n">random</span>
<span class="kn">import</span> <span class="n">torch.nn</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">flag</span> <span class="o">=</span> <span class="sh">"</span><span class="s">TCP1P{}</span><span class="sh">"</span>

<span class="k">def</span> <span class="nf">floatify</span><span class="p">(</span><span class="n">ip</span><span class="p">):</span>
	<span class="n">flag</span> <span class="o">=</span> <span class="p">[</span><span class="nf">float</span><span class="p">(</span><span class="nf">ord</span><span class="p">(</span><span class="n">i</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ip</span><span class="p">]</span>
	<span class="n">normalized</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="n">flag</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
    
	<span class="k">return</span> <span class="n">normalized</span>
<span class="k">def</span> <span class="nf">tf</span><span class="p">(</span><span class="n">_in</span><span class="p">,</span><span class="n">_out</span><span class="p">):</span>
	<span class="n">weight</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">round</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="n">_out</span><span class="p">,</span> <span class="n">_in</span><span class="p">)).</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">),</span><span class="mi">2</span><span class="p">)</span>
	<span class="n">bias</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">round</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">_out</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">),</span><span class="mi">2</span><span class="p">)</span>
	<span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">from_numpy</span><span class="p">(</span><span class="n">weight</span><span class="p">),</span> <span class="n">torch</span><span class="p">.</span><span class="nf">from_numpy</span><span class="p">(</span><span class="n">bias</span><span class="p">)</span>

<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="mh">0x544350</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
	<span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="mi">450</span><span class="p">),</span>
	<span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">450</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span>
	<span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">17</span><span class="p">)</span>
<span class="p">)</span>


<span class="n">layer_shapes</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">24</span><span class="p">,</span> <span class="mi">450</span><span class="p">),</span> <span class="p">(</span><span class="mi">450</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">17</span><span class="p">)]</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">layer_shapes</span><span class="p">):</span>
	<span class="n">weight</span><span class="p">,</span> <span class="n">bias</span> <span class="o">=</span> <span class="nf">tf</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>
	<span class="n">model</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">weight</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">weight</span>
	<span class="n">model</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">bias</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">bias</span>
 

<span class="c1"># Output:
# [38883.9140625, 18747.87890625, -15371.05078125, 12231.2080078125, -56379.48046875, -33719.13671875, 9454.150390625, 9346.9814453125, 1701.4693603515625, -6380.3759765625, 12019.501953125, -4850.94140625, 14421.296875, 44332.0390625, -11196.283203125, -19712.0859375, -36390.265625]
</span>
<span class="n">output</span> <span class="o">=</span> <span class="p">[</span><span class="mf">38883.9140625</span><span class="p">,</span> <span class="mf">18747.87890625</span><span class="p">,</span> <span class="o">-</span><span class="mf">15371.05078125</span><span class="p">,</span> <span class="mf">12231.2080078125</span><span class="p">,</span> <span class="o">-</span><span class="mf">56379.48046875</span><span class="p">,</span> <span class="o">-</span><span class="mf">33719.13671875</span><span class="p">,</span> <span class="mf">9454.150390625</span><span class="p">,</span> <span class="mf">9346.9814453125</span><span class="p">,</span> <span class="mf">1701.4693603515625</span><span class="p">,</span> <span class="o">-</span><span class="mf">6380.3759765625</span><span class="p">,</span> <span class="mf">12019.501953125</span><span class="p">,</span> <span class="o">-</span><span class="mf">4850.94140625</span><span class="p">,</span> <span class="mf">14421.296875</span><span class="p">,</span> <span class="mf">44332.0390625</span><span class="p">,</span> <span class="o">-</span><span class="mf">11196.283203125</span><span class="p">,</span> <span class="o">-</span><span class="mf">19712.0859375</span><span class="p">,</span> <span class="o">-</span><span class="mf">36390.265625</span><span class="p">]</span>

<span class="c1">#convert the output into a format PyTorch can use
</span><span class="n">target_output</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="n">output</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>


<span class="c1"># Known characters of the flag
</span><span class="n">first_six_chars</span> <span class="o">=</span> <span class="sh">"</span><span class="s">TCP1P{</span><span class="sh">"</span>  <span class="c1"># Known prefix
</span><span class="n">last_char</span> <span class="o">=</span> <span class="sh">"</span><span class="s">}</span><span class="sh">"</span>              <span class="c1"># Known suffix
</span>
<span class="c1"># Construct the initial flag candidate
</span><span class="n">known_chars</span> <span class="o">=</span> <span class="p">[</span><span class="nf">ord</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">first_six_chars</span><span class="p">]</span>
<span class="n">middle_length</span> <span class="o">=</span> <span class="mi">17</span>  <span class="c1"># Total length is 24; 6 + middle + 1 = 24, so 17 middle characters
</span><span class="n">middle_chars</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">middle_length</span><span class="p">)).</span><span class="nf">tolist</span><span class="p">()</span>  <span class="c1"># Random initial middle characters
</span><span class="n">known_chars</span> <span class="o">+=</span> <span class="n">middle_chars</span> <span class="o">+</span> <span class="p">[</span><span class="nf">ord</span><span class="p">(</span><span class="n">last_char</span><span class="p">)]</span>

<span class="c1"># Create an input tensor with the known characters
</span><span class="n">input_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="n">known_chars</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># Target output (adjust according to your expectations)
</span>
<span class="c1"># Optimiser setup
</span><span class="n">optimiser</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">([</span><span class="n">input_tensor</span><span class="p">],</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>  <span class="c1"># Learning rate
</span>
<span class="c1"># Number of iterations for optimisation
</span><span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">50000</span>

<span class="c1"># Gradient-based optimisation loop
</span><span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">):</span>
    <span class="n">optimiser</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>  <span class="c1"># Zero out the gradients
</span>
    <span class="c1"># Forward pass through the model
</span>    <span class="n">output</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>

    <span class="c1"># Compute the loss
</span>    <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">mse_loss</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target_output</span><span class="p">)</span>
    
    <span class="c1"># If loss is zero break from training loop
</span>    <span class="k">if</span> <span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">:</span>
        <span class="k">break</span>

    <span class="c1"># Backward pass (compute gradients)
</span>    <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>

    <span class="c1"># Gradient update step
</span>    <span class="n">optimiser</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>

    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>

        <span class="c1"># Ensure the first six and last character are fixed
</span>        <span class="n">input_tensor</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:</span><span class="mi">6</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="nf">ord</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">first_six_chars</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">input_tensor</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="nf">ord</span><span class="p">(</span><span class="n">last_char</span><span class="p">)</span>

    <span class="c1">#print progress
</span>    <span class="k">if</span> <span class="n">iteration</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Iteration </span><span class="si">{</span><span class="n">iteration</span><span class="si">}</span><span class="s">, Loss: </span><span class="si">{</span><span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    

<span class="c1"># Convert the optimised input tensor back to a flag candidate
</span><span class="n">optimised_flag</span> <span class="o">=</span> <span class="sh">""</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="nf">chr</span><span class="p">(</span><span class="nf">int</span><span class="p">(</span><span class="nf">round</span><span class="p">(</span><span class="n">c</span><span class="p">)))</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">input_tensor</span><span class="p">.</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Optimised Flag Candidate: </span><span class="si">{</span><span class="n">optimised_flag</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/htb-weak-rsa/">Hack The Box - Weak RSA</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/tcp1p-2024-skibidi-format/">TCP1P 2024 - Skibidi Format</a> </li> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2025 Joshua R. Sylvester. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>